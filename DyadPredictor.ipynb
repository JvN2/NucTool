{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dyad Position Predictor\n",
    "Train a neural network to predict dyad positions on a per-position basis from encoded DNA sequences (0-7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and setup\n",
    "Load core libraries (NumPy, PyTorch, Matplotlib), utilities, and project helpers used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from ChromatinFibers import simulate_chromatin_fibers, SimulationParams, read_simulation_results\n",
    "from Plotter import SequencePlotter\n",
    "\n",
    "plotter = SequencePlotter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simulation parameters and output paths\n",
    "Choose how many samples to simulate and define file paths for saving the model and generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filename = rf\"data/LLM models/test_15000.h5\"\n",
    "\n",
    "n_samples = 150\n",
    "model_filename = rf\"data/LLM models/test_{n_samples}.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Simulation new data\n",
    "Only if not enough data is available, simulate new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(data_filename).exists():\n",
    "    data_simulation_params = read_simulation_results(data_filename)\n",
    "    if data_simulation_params.n_samples < n_samples:\n",
    "        simulation_params = data_simulation_params\n",
    "        simulation_params.n_samples = n_samples - data_simulation_params.n_samples\n",
    "        simulate_chromatin_fibers(simulation_params, data_filename)\n",
    "else:\n",
    "    simulation_params = SimulationParams(n_samples=n_samples)\n",
    "    simulate_chromatin_fibers(simulation_params, data_filename)\n",
    "\n",
    "simulation_params = read_simulation_results(data_filename)\n",
    "print(\"Simulation parameters:\")\n",
    "for key, value in simulation_params.__dict__.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model architecture visualization\n",
    "Define and render a step-by-step diagram explaining how the model transforms an input sequence into per-position dyad probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the LLM; diagram of data flow through the model\n",
    "# not required for full operation\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "\n",
    "def visualize_model_forward_pass(sequence_length=100):\n",
    "    \"\"\"\n",
    "    Create a visual diagram showing how data flows through the model.\n",
    "    Uses a toy example with shapes to illustrate transformations.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Model hyperparameters (matching the actual model)\n",
    "    embedding_dim = 16\n",
    "    hidden_dim = 64\n",
    "\n",
    "    # Shared box geometry for Steps 2–4\n",
    "    BOX_HEIGHT = 0.20\n",
    "    ROW_STEP = 0.24  # vertical step between rows\n",
    "    \n",
    "    # Use constrained_layout to avoid tight_layout warnings and improve spacing\n",
    "    fig = plt.figure(figsize=(16, 12), constrained_layout=True)\n",
    "    # Reorder: summary diagram at top (rows 0-1), then steps 1-5 (rows 2-7)\n",
    "    gs = GridSpec(8, 3, figure=fig, height_ratios=[1.5, 1.5, 1, 1, 1.3, 2.1, 2, 0.2])\n",
    "    # Increase vertical space between rows (steps)\n",
    "    fig.set_constrained_layout_pads(w_pad=0.05, h_pad=0.05, hspace=0.3, wspace=0.2)\n",
    "    \n",
    "    # Define colors for different stages\n",
    "    colors = {\n",
    "        'input': \"#DDF033\",      # Light yellow\n",
    "        'embed': '#B4D7FF',      # Light blue\n",
    "        'conv': '#B4FFB4',       # Light green\n",
    "        'lstm': '#FFB4E5',       # Light pink\n",
    "        'output': '#FFD4B4'      # Light orange\n",
    "    }\n",
    "    \n",
    "    # ========== Summary Diagram (NOW AT TOP) ==========\n",
    "    ax_summary = fig.add_subplot(gs[0:2, :])\n",
    "    fig.text(0.01, 1.0, 'A)', fontsize=18, fontweight='bold', va='top')\n",
    "    ax_summary.axis('off')\n",
    "    \n",
    "    # Create flow diagram\n",
    "    boxes = [\n",
    "        ('Input\\nIntegers', 0.5, colors['input']),\n",
    "        ('Embedding\\n(State Space)', 1.5, colors['embed']),\n",
    "        ('Conv Layers\\n(Local \\nInteractions)', 2.5, colors['conv']),\n",
    "        ('BiLSTM\\n(Long-range \\nCoupling)', 3.5, colors['lstm']),\n",
    "        ('MLP +\\n Sigmoid\\n(Per-site \\nEnergy)', 4.5, colors['output'])\n",
    "    ]\n",
    "    \n",
    "    for label, x, color in boxes:\n",
    "        rect = mpatches.FancyBboxPatch((x-0.35, 0.5), 0.7, 0.4, \n",
    "                                       boxstyle=\"round,pad=0.05\", \n",
    "                                       facecolor=color, \n",
    "                                       edgecolor='black', linewidth=2)\n",
    "        ax_summary.add_patch(rect)\n",
    "        ax_summary.text(x, 0.7, label, ha='center', va='center', \n",
    "                fontsize=14, fontweight='bold')\n",
    "        \n",
    "        if x < 4.5:\n",
    "            ax_summary.arrow(x+0.35, 0.7, 0.25, 0, head_width=0.1, head_length=0.08, \n",
    "                     fc='black', ec='black', linewidth=2)\n",
    "    \n",
    "    # Add physics analogies\n",
    "    label_height = 0.35\n",
    "    analogies = [\n",
    "        (0.5, label_height, 'Discrete\\nstates'),\n",
    "        (1.5, label_height, 'Continuous\\ncoordinates'),\n",
    "        (2.5, label_height, 'Nearest-\\nneighbor'),\n",
    "        (3.5, label_height, 'Mean-field\\neffects'),\n",
    "        (4.5, label_height, 'Observable\\n(probability)')\n",
    "    ]\n",
    "    \n",
    "    for x, y, text in analogies:\n",
    "        ax_summary.text(x, y, text, ha='center', va='top', \n",
    "                fontsize=14, style='italic', color='blue')\n",
    "    \n",
    "    ax_summary.set_xlim(0, 5.5)\n",
    "    ax_summary.set_ylim(0.25, 1.05)\n",
    "    \n",
    "    # ========== 1. Input Sequence ==========\n",
    "    ax1 = fig.add_subplot(gs[2, :])\n",
    "    ax1.set_title('Step 1: Input Sequence (Encoded methylated DNA)', fontsize=16, fontweight='bold')\n",
    "    fig.text(0.01, 0.77, 'B)', fontsize=18, fontweight='bold', va='top')\n",
    "    \n",
    "    # Show a small example sequence\n",
    "    example_seq = [2, 5, 1, 7, 3, 4, 6, 0, 2, 5, 1, 7]\n",
    "    n_show = len(example_seq)\n",
    "    \n",
    "    for i, val in enumerate(example_seq):\n",
    "        rect = mpatches.Rectangle((i, 0), 0.9, 0.9, \n",
    "                                  facecolor=colors['input'], \n",
    "                                  edgecolor='black', linewidth=1.5)\n",
    "        ax1.add_patch(rect)\n",
    "        ax1.text(i + 0.45, 0.45, str(val), \n",
    "                ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    ax1.set_xlim(-0.5, n_show)\n",
    "    ax1.set_ylim(-0.2, 1.2)\n",
    "    ax1.axis('off')\n",
    "    ax1.text(n_show/2, -0.5, 'Each number (0-7) encodes base + modifications', \n",
    "            ha='center', fontsize=14, color='gray')\n",
    "    \n",
    "    # ========== 2. Embedding Layer ==========\n",
    "    ax2 = fig.add_subplot(gs[3, :])\n",
    "    ax2.set_title('Step 2: Embedding (Lookup Table)', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Show embedding as small vertical bars (uniform height)\n",
    "    embed_rows = 4\n",
    "    for i in range(n_show):\n",
    "        for j in range(embed_rows):  # Show 4 dimensions for visualization\n",
    "            intensity = np.random.rand() * 0.7 + 0.3\n",
    "            y0 = j * ROW_STEP\n",
    "            rect = mpatches.Rectangle((i, y0), 0.9, BOX_HEIGHT, \n",
    "                                      facecolor=colors['embed'], \n",
    "                                      edgecolor='black', linewidth=0.5,\n",
    "                                      alpha=intensity)\n",
    "            ax2.add_patch(rect)\n",
    "    \n",
    "    ax2.set_xlim(-0.5, n_show)\n",
    "    ax2.set_ylim(-0.1, ROW_STEP*(embed_rows-1) + BOX_HEIGHT + 0.1)\n",
    "    ax2.axis('off')\n",
    "    ax2.text(n_show/2, -0.5, f'Each integer mapped to dense vector (like a learned coordinate) | embed_dim={embedding_dim}', \n",
    "            ha='center', fontsize=14, color='gray')\n",
    "    \n",
    "    # ========== 3. Conv Layer 1 ==========\n",
    "    ax3 = fig.add_subplot(gs[4, :])\n",
    "    ax3.set_title('Step 3: Convolution Layers (Local Pattern Detection)', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Show convolution as sliding windows\n",
    "    kernel_size = 5\n",
    "    conv_rows = 6\n",
    "    y_max3 = ROW_STEP*(conv_rows-1) + BOX_HEIGHT\n",
    "    for i in range(n_show - kernel_size + 1):\n",
    "        # Highlight receptive field\n",
    "        if i % 3 == 0:  # Show every 3rd for clarity\n",
    "            rect_bg = mpatches.Rectangle((i, 0), kernel_size*0.9, y_max3, \n",
    "                                         facecolor='yellow', alpha=0.6, \n",
    "                                         edgecolor='red', linewidth=2, linestyle='--')\n",
    "            ax3.add_patch(rect_bg)\n",
    "    \n",
    "    for i in range(n_show):\n",
    "        for j in range(conv_rows):\n",
    "            intensity = np.random.rand() * 0.6 + 0.4\n",
    "            y0 = j * ROW_STEP\n",
    "            rect = mpatches.Rectangle((i, y0), 0.9, BOX_HEIGHT, \n",
    "                                      facecolor=colors['conv'], \n",
    "                                      edgecolor='black', linewidth=0.5,\n",
    "                                      alpha=intensity)\n",
    "            ax3.add_patch(rect)\n",
    "    \n",
    "    ax3.set_xlim(-0.5, n_show)\n",
    "    ax3.set_ylim(-0.1, y_max3 + 0.1)\n",
    "    ax3.axis('off')\n",
    "    ax3.text(n_show/2, -0.5, f'Conv kernels (size=5) detect local motifs, like \"TATA box\" patterns | hidden_dim={hidden_dim}', \n",
    "            ha='center', fontsize=14, color='gray')\n",
    "    \n",
    "    # ========== 4. BiLSTM Layer ==========\n",
    "    ax4 = fig.add_subplot(gs[5, :])\n",
    "    ax4.set_title('Step 4: Bidirectional LSTM (Global Context)', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    lstm_rows = 6\n",
    "    y_max4 = ROW_STEP*(lstm_rows-1) + BOX_HEIGHT*4\n",
    "    # Show information flow with arrows\n",
    "    for i in range(n_show):\n",
    "        for j in range(lstm_rows):\n",
    "            intensity = np.random.rand() * 0.5 + 0.5\n",
    "            y0 = j * ROW_STEP\n",
    "            rect = mpatches.Rectangle((i, y0), 0.9, BOX_HEIGHT, \n",
    "                                      facecolor=colors['lstm'], \n",
    "                                      edgecolor='black', linewidth=0.5,\n",
    "                                      alpha=intensity)\n",
    "            ax4.add_patch(rect)\n",
    "    \n",
    "    # Draw arrows showing bidirectional flow (positioned near the top of the band)\n",
    "    arrow_y = max(0.15, y_max4 - 0.05)\n",
    "    ax4.arrow(1, arrow_y, n_show-3, 0, head_width=0.08, head_length=0.5, \n",
    "             fc='blue', ec='blue', alpha=0.5, linewidth=2)\n",
    "    ax4.arrow(n_show-2, arrow_y-0.15, -(n_show-3), 0, head_width=0.08, head_length=0.5, \n",
    "             fc='red', ec='red', alpha=0.5, linewidth=2)\n",
    "    \n",
    "    ax4.text(n_show/2, arrow_y+0.1, 'Forward →', ha='center', fontsize=14, color='blue')\n",
    "    ax4.text(n_show/2, arrow_y-0.45, '← Backward', ha='center', fontsize=14, color='red')\n",
    "    \n",
    "    ax4.set_xlim(-0.5, n_show)\n",
    "    ax4.set_ylim(-0.1, y_max4 + 0.25)\n",
    "    ax4.axis('off')\n",
    "    ax4.text(n_show/2, -0.5, f'LSTM integrates context from both directions—like considering neighbors in statistical physics | hidden_dim={hidden_dim}', \n",
    "            ha='center', fontsize=14, color='gray')\n",
    "    \n",
    "    # ========== 5. Output Layer ==========\n",
    "    ax5 = fig.add_subplot(gs[6, :])\n",
    "    ax5.set_title('Step 5: Per-Position Classifier (MLP + Sigmoid)', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Show output as probability bars\n",
    "    np.random.seed(42)\n",
    "    probs = np.random.beta(2, 10, n_show)  # Skewed distribution (most low, few high)\n",
    "    probs[[3, 8]] = [0.85, 0.92]  # Make two positions \"dyads\"\n",
    "    \n",
    "    for i in range(n_show):\n",
    "        # Probability bar\n",
    "        rect = mpatches.Rectangle((i, 0), 0.9, probs[i], \n",
    "                                  facecolor=colors['output'], \n",
    "                                  edgecolor='black', linewidth=1)\n",
    "        ax5.add_patch(rect)\n",
    "        \n",
    "        # Mark high-confidence predictions\n",
    "        if probs[i] > 0.5:\n",
    "            ax5.plot(i + 0.45, probs[i] + 0.08, 'v', \n",
    "                    color='red', markersize=10, markeredgecolor='black')\n",
    "    \n",
    "    ax5.axhline(y=0.5, color='red', linestyle='--', linewidth=1.5, alpha=0.7, label='Threshold')\n",
    "    ax5.set_xlim(-0.5, n_show)\n",
    "    ax5.set_ylim(-0.1, 1.2)\n",
    "    ax5.set_ylabel('Probability', fontsize=14)\n",
    "    ax5.spines['top'].set_visible(False)\n",
    "    ax5.spines['right'].set_visible(False)\n",
    "    ax5.spines['left'].set_linewidth(1.5)\n",
    "    ax5.spines['bottom'].set_linewidth(1.5)\n",
    "    ax5.text(n_show/2, -0.5, f'Each position gets a dyad probability (0-1) | hidden_dim={hidden_dim}', \n",
    "            ha='center', fontsize=14, color='gray')\n",
    "    ax5.legend(loc='upper right', fontsize=14)\n",
    "    \n",
    "    caption = \"A) Model architecture overview of DyadPredictor: Full architecture flow showing how discrete DNA sequences are mapped to continuous embeddings, processed through local pattern detectors (convolutions) and global context integrators (bidirectional LSTM), and finally decoded to per-position dyad probabilities. B) Detailed data flow: from DNA sequence and methylations to dyad probability predictions. \"\n",
    "    caption += \"The model combines local pattern detection (convolutions) with global context integration (Bidirectional LSTM), \"\n",
    "    caption += \"similar to how a spin system has both nearest-neighbor interactions and long-range correlations. Physics interpretation: \"\n",
    "    caption += \"\"\"\n",
    "    Step 1) Input Layer: Like preparing a measurement—discrete observable states.\n",
    "    Step 2) Embedding: Maps discrete symbols to continuous vector space. Analogous to choosing a basis for your Hilbert space.\n",
    "    Step 3) Convolutions: Apply local filters (like correlation functions). Detect short-range order, similar to pair correlation g(r).\n",
    "    Step 4) Bidirectional LSTM (Long Short-Term Memory): Propagates information bidirectionally. Like solving a 1D diffusion equation or computing transfer matrix. Captures long-range dependencies (think Debye screening length).\n",
    "    Step 5) Output: Per-position \"field\" of dyad probability via Multi-Layer Perceptron (MLP). Observable quantity, like local magnetization m(x) or density ρ(x).\n",
    "    The loss function (weighted Binary Cross-Entropy) is like minimizing free energy with constraints, where pos_weight accounts for rare-event statistics.\n",
    "    \"\"\"\n",
    "\n",
    "    plotter.add_caption(caption)\n",
    "\n",
    "    return fig\n",
    "\n",
    "# Create the visualization\n",
    "fig = visualize_model_forward_pass(sequence_length=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify data file exists\n",
    "Check that the HDF5 data file exists from the simulation in the previous cell. Load simulation parameters from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify HDF5 data file exists and load parameters\n",
    "if Path(data_filename).exists():\n",
    "    print(f\"Data file verified: {data_filename}\")\n",
    "    \n",
    "    # Load simulation parameters from HDF5 file\n",
    "    loaded_params = read_simulation_results(data_filename)\n",
    "    print(\"\\nLoaded simulation parameters:\")\n",
    "    for key, value in loaded_params.__dict__.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Write simulation parameters to JSON config for reference\n",
    "    config_path = Path(model_filename).with_suffix(\".json\")\n",
    "    \n",
    "    if config_path.exists():\n",
    "        with open(config_path, \"r\") as f:\n",
    "            existing_config = json.load(f)\n",
    "    else:\n",
    "        existing_config = {}\n",
    "    \n",
    "    existing_config[\"simulation\"] = loaded_params.__dict__\n",
    "    \n",
    "    with open(config_path, \"w\") as f:\n",
    "        json.dump(existing_config, f, indent=4)\n",
    "    \n",
    "    print(f\"\\nConfig saved to: {config_path}\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Data file not found: {data_filename}. Run the simulation cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define model architecture (PyTorch)\n",
    "Build the DyadPredictor network: embedding, convolutional blocks for local motifs, BiLSTM for context, and a per-position classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DyadPredictor(nn.Module):\n",
    "    \"\"\"Per-position dyad predictor using Conv1d and bidirectional context.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, vocab_size=8, embedding_dim=16, hidden_dim=64, num_layers=2, dropout=0.3\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        # Embedding layer (map 0-7 to dense vectors)\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # Conv blocks for local context\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        # BiLSTM for global context\n",
    "        self.lstm = nn.LSTM(\n",
    "            hidden_dim,\n",
    "            hidden_dim // 2,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        # Output head\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass.\n",
    "        Args:\n",
    "            x: (batch_size, seq_len) - encoded sequence\n",
    "        Returns:\n",
    "            logits: (batch_size, seq_len, 1) - per-position dyad logits\n",
    "        \"\"\"\n",
    "        # Embedding: (batch, seq_len) -> (batch, seq_len, embed_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # Conv blocks: (batch, seq_len, embed_dim) -> (batch, embed_dim, seq_len)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # Back to (batch, seq_len, hidden_dim)\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        # LSTM: (batch, seq_len, hidden_dim) -> (batch, seq_len, hidden_dim)\n",
    "        x, _ = self.lstm(x)\n",
    "\n",
    "        # Per-position classification: (batch, seq_len, hidden_dim) -> (batch, seq_len, 1)\n",
    "        logits = self.fc(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define custom Dataset (HDF5-based)\n",
    "Implement a Dataset that loads samples on-demand from the HDF5 file using read_simulation_results, pads sequences, and marks padding with -1 in labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DyadDataset(Dataset):\n",
    "    \"\"\"HDF5-based dataset for dyad position prediction - loads data on-demand from disk.\"\"\"\n",
    "\n",
    "    def __init__(self, data_filename, indices=None, max_seq_len=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_filename: path to .h5 file containing dyad positions and encoded sequences\n",
    "            indices: list of sample indices to use (for train/val/test split)\n",
    "            max_seq_len: optional, pad/truncate sequences to this length\n",
    "        \"\"\"\n",
    "        self.data_filename = data_filename\n",
    "        self.indices = indices\n",
    "\n",
    "        # Load metadata from HDF5 to determine dataset size and max_seq_len\n",
    "        params = read_simulation_results(data_filename)\n",
    "        self.n_total_samples = params.n_samples\n",
    "\n",
    "        # Use the known sequence length from simulation parameters\n",
    "        if max_seq_len is None:\n",
    "            self.max_seq_len = params.length_bp\n",
    "        else:\n",
    "            self.max_seq_len = max_seq_len\n",
    "\n",
    "        # Default to all samples if no indices provided\n",
    "        if self.indices is None:\n",
    "            self.indices = list(range(self.n_total_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Map dataset index to actual file index\n",
    "        real_idx = self.indices[idx]\n",
    "\n",
    "        # Load only the requested sample from HDF5\n",
    "        dyad_pos, encoded_seq, _ = read_simulation_results(self.data_filename, real_idx)\n",
    "\n",
    "        # Convert to regular numpy arrays\n",
    "        dyad_pos = np.asarray(dyad_pos, dtype=np.int64)\n",
    "        encoded_seq = np.asarray(encoded_seq, dtype=np.int64)\n",
    "\n",
    "        seq_len = len(encoded_seq)\n",
    "\n",
    "        # Create binary label: 1 if dyad at position, 0 otherwise\n",
    "        label = np.zeros(seq_len, dtype=np.float32)\n",
    "        for pos in dyad_pos:\n",
    "            if 0 <= pos < seq_len:\n",
    "                label[pos] = 1.0\n",
    "\n",
    "        # Convert to tensors\n",
    "        seq_tensor = torch.LongTensor(encoded_seq)\n",
    "        label_tensor = torch.FloatTensor(label)\n",
    "\n",
    "        # Pad/truncate to max_seq_len\n",
    "        if seq_len < self.max_seq_len:\n",
    "            pad_len = self.max_seq_len - seq_len\n",
    "            seq_tensor = torch.nn.functional.pad(seq_tensor, (0, pad_len), value=0)\n",
    "            label_tensor = torch.nn.functional.pad(\n",
    "                label_tensor, (0, pad_len), value=-1\n",
    "            )  # -1 for padding\n",
    "        elif seq_len > self.max_seq_len:\n",
    "            seq_tensor = seq_tensor[: self.max_seq_len]\n",
    "            label_tensor = label_tensor[: self.max_seq_len]\n",
    "\n",
    "        return seq_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create train/validation/test index splits\n",
    "Derive index-based splits from the HDF5 file metadata without loading data into RAM, enabling scalable training on large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/val/test split using indices (no data loaded into memory yet)\n",
    "# This approach scales to arbitrarily large datasets\n",
    "\n",
    "# Get total number of samples from HDF5 file\n",
    "params = read_simulation_results(data_filename)\n",
    "n_total = params.n_samples\n",
    "\n",
    "# Split indices for train/val/test\n",
    "n_train = int(0.7 * n_samples)\n",
    "n_val = int(0.15 * n_samples)\n",
    "\n",
    "train_indices = list(range(n_train))\n",
    "val_indices = list(range(n_train, n_train + n_val))\n",
    "test_indices = list(range(n_train + n_val, n_samples))\n",
    "\n",
    "print(f\"Total samples in HDF5 file: {n_total}\")\n",
    "print(f\"Using {n_samples} samples ({n_samples/n_total*100:.1f}%)\")\n",
    "print(f\"Dataset split - Train: {len(train_indices)}, Val: {len(val_indices)}, Test: {len(test_indices)}\")\n",
    "print(f\"HDF5 mode: Data will be loaded on-demand during training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create DataLoaders\n",
    "Wrap the HDF5-based datasets in DataLoaders with batching and optional multiprocessing/pinned memory for faster throughput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HDF5-based datasets (data loaded on-demand, not held in RAM)\n",
    "# Use the known sequence length from simulation parameters\n",
    "params = read_simulation_results(data_filename)\n",
    "KNOWN_SEQ_LEN = params.length_bp\n",
    "\n",
    "train_dataset = DyadDataset(\n",
    "    data_filename, indices=train_indices, max_seq_len=KNOWN_SEQ_LEN\n",
    ")\n",
    "val_dataset = DyadDataset(\n",
    "    data_filename, indices=val_indices, max_seq_len=KNOWN_SEQ_LEN\n",
    ")\n",
    "test_dataset = DyadDataset(\n",
    "    data_filename, indices=test_indices, max_seq_len=KNOWN_SEQ_LEN\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Enable multi-processing to parallelize disk I/O\n",
    "# Set num_workers=0 if you get slow startup or notebook multiprocessing issues\n",
    "cpu_count = os.cpu_count() or 2\n",
    "# On Windows (spawn start method) DataLoader worker processes frequently fail inside notebooks.\n",
    "# Use single-process data loading in notebooks on Windows to avoid 'worker exited unexpectedly' errors.\n",
    "if os.name == 'nt':\n",
    "    num_workers = 0\n",
    "else:\n",
    "    num_workers = max(0, min(4, (cpu_count - 1)))  # Adjust based on your CPU cores\n",
    "pin_memory = torch.cuda.is_available()\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    persistent_workers=True if num_workers > 0 else False,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    persistent_workers=True if num_workers > 0 else False,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    persistent_workers=True if num_workers > 0 else False,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "\n",
    "print(f\"Max sequence length (used): {KNOWN_SEQ_LEN}\")\n",
    "print(\n",
    "    f\"DataLoaders created: train={len(train_loader)} batches, val={len(val_loader)}, test={len(test_loader)}\"\n",
    ")\n",
    "print(f\"Using {num_workers} worker processes for data loading\")\n",
    "print(f\"Pin memory: {pin_memory}\")\n",
    "print(\"Tip: If this cell starts slow, it's usually worker process startup; set num_workers=0 above for instant startup in notebooks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Initialize model, loss, optimizer, and AMP\n",
    "Move the model to the selected device, define the loss and optimizer, configure LR scheduler, and enable AMP on CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = DyadPredictor(\n",
    "    vocab_size=8, embedding_dim=16, hidden_dim=64, num_layers=2, dropout=0.3\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function: BCEWithLogitsLoss (combines sigmoid + BCE)\n",
    "pos_weight = torch.tensor([10.0]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight, reduction=\"none\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "# ReduceLROnPlateau without 'verbose' for compatibility with older PyTorch versions\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=3\n",
    ")\n",
    "\n",
    "# Enable mixed precision on CUDA for speed/memory savings\n",
    "use_amp = torch.cuda.is_available()\n",
    "# Create a GradScaler for AMP. Do NOT pass a device string as the first positional arg;\n",
    "# the correct usage is torch.amp.GradScaler(enabled=...) or torch.cuda.amp.GradScaler().\n",
    "scaler = torch.amp.GradScaler(enabled=use_amp)\n",
    "print(f\"AMP enabled: {use_amp}\")\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Compute class imbalance weight (pos_weight)\n",
    "Estimate pos_weight = negatives/positives using a fast sampler over the training indices to balance the BCE loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast computation of pos_weight from training data (ignores padding)\n",
    "from typing import Optional\n",
    "import math\n",
    "\n",
    "def compute_pos_weight(data_filename: str, indices, sample_size: Optional[int] = 500, seed: int = 42):\n",
    "    \"\"\"Estimate pos_weight = neg/pos quickly by sampling train indices from HDF5.\n",
    "\n",
    "    This opens the HDF5 file and reads only the sampled sequences to count:\n",
    "      - positives = number of dyad positions (len(dyad_positions[i]))\n",
    "      - negatives = sequence length - positives (len(encoded_seq[i]) - positives)\n",
    "\n",
    "    Args:\n",
    "        data_filename: path to the .h5 file\n",
    "        indices: iterable of indices representing the training set\n",
    "        sample_size: number of samples to draw from indices (None means use all, which may be slow)\n",
    "        seed: RNG seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor with shape [1], dtype float32, value = neg/pos (clamped if needed later)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    indices = np.asarray(list(indices))\n",
    "    if indices.size == 0:\n",
    "        raise ValueError(\"No indices provided to compute_pos_weight\")\n",
    "\n",
    "    if sample_size is None:\n",
    "        sample_indices = indices\n",
    "    else:\n",
    "        k = min(int(sample_size), indices.size)\n",
    "        sample_indices = rng.choice(indices, size=k, replace=False)\n",
    "\n",
    "    pos_total = 0\n",
    "    neg_total = 0\n",
    "    \n",
    "    # Read samples from HDF5 using read_simulation_results\n",
    "    for i in sample_indices:\n",
    "        dyad_positions, encoded_seq, _ = read_simulation_results(data_filename, int(i))\n",
    "        \n",
    "        # Count positives as number of dyad positions\n",
    "        n_pos = len(dyad_positions)\n",
    "        # Negatives are remaining real (unpadded) positions\n",
    "        seq_len = len(encoded_seq)\n",
    "        n_neg = max(seq_len - n_pos, 0)\n",
    "        pos_total += n_pos\n",
    "        neg_total += n_neg\n",
    "\n",
    "    if pos_total == 0:\n",
    "        # Fallback to avoid division by zero; assume at least one positive overall\n",
    "        print(\"Warning: no positives found in sample; defaulting pos_total=1 for stability.\")\n",
    "        pos_total = 1\n",
    "\n",
    "    pw = float(neg_total) / float(pos_total)\n",
    "    return torch.tensor([pw], dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "# Compute and clamp pos_weight quickly using a sample of the training set\n",
    "SAMPLE_SIZE_FOR_POS_WEIGHT = 500  # adjust for more accuracy vs speed\n",
    "pos_weight = compute_pos_weight(data_filename, train_indices, sample_size=SAMPLE_SIZE_FOR_POS_WEIGHT).to(device)\n",
    "pos_weight = torch.clamp(pos_weight, min=1.0, max=100.0)\n",
    "print(f\"Computed pos_weight (sample n={min(SAMPLE_SIZE_FOR_POS_WEIGHT, len(train_indices))}): {pos_weight.item():.4f}\")\n",
    "\n",
    "# Define the weighted criterion (reduction='none' so you can mask padding later)\n",
    "criterion_weighted = nn.BCEWithLogitsLoss(pos_weight=pos_weight, reduction=\"none\")\n",
    "\n",
    "# Save LLM configuration to JSON\n",
    "config_path = Path(model_filename).with_suffix(\".json\")\n",
    "if config_path.exists():\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "else:\n",
    "    config = {}\n",
    "\n",
    "config[\"llm\"] = {\n",
    "    \"vocab_size\": 8,\n",
    "    \"embedding_dim\": 16,\n",
    "    \"hidden_dim\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.3,\n",
    "    \"pos_weight\": float(pos_weight.item()),\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler\": \"ReduceLROnPlateau\",\n",
    "}\n",
    "\n",
    "with open(config_path, \"w\") as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "print(f\"LLM configuration saved to: {config_path}\")\n",
    "\n",
    "# Expose for REPL visibility\n",
    "criterion_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Define training and validation loops\n",
    "Implement efficient training with masking of padded positions, AMP support, gradient clipping, and early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device, scaler=None, use_amp=False, max_batches=None):\n",
    "    \"\"\"Train for one epoch.\n",
    "    Args:\n",
    "        model, train_loader, criterion, optimizer, device: standard\n",
    "        scaler: GradScaler for AMP (optional)\n",
    "        use_amp: bool, enable autocast on CUDA\n",
    "        max_batches: int or None, limit number of batches per epoch for faster iterations\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (seq_batch, label_batch) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
    "        seq_batch = seq_batch.to(device, non_blocking=True)  # (batch, seq_len)\n",
    "        label_batch = label_batch.to(device, non_blocking=True)  # (batch, seq_len)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Forward pass\n",
    "        with torch.amp.autocast('cuda', enabled=use_amp):\n",
    "            logits = model(seq_batch)  # (batch, seq_len, 1)\n",
    "            logits = logits.squeeze(-1)  # (batch, seq_len)\n",
    "\n",
    "            # Compute loss (ignore padding positions with label=-1)\n",
    "            loss_per_pos = criterion(logits, label_batch)  # (batch, seq_len)\n",
    "            mask = (label_batch >= 0).float()  # Mask out padding\n",
    "            loss = (loss_per_pos * mask).sum() / mask.sum().clamp(min=1)\n",
    "\n",
    "        if scaler is not None and use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            # Unscale for clipping\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if max_batches is not None and (batch_idx + 1) >= max_batches:\n",
    "            break\n",
    "\n",
    "    return total_loss / max(1, (batch_idx + 1))\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device, use_amp=False, max_batches=None):\n",
    "    \"\"\"Validate model with optional batch limit.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (seq_batch, label_batch) in enumerate(tqdm(val_loader, desc=\"Validating\")):\n",
    "            seq_batch = seq_batch.to(device, non_blocking=True)\n",
    "            label_batch = label_batch.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.amp.autocast('cuda', enabled=use_amp):\n",
    "                logits = model(seq_batch)\n",
    "                logits = logits.squeeze(-1)\n",
    "\n",
    "                loss_per_pos = criterion(logits, label_batch)\n",
    "                mask = (label_batch >= 0).float()\n",
    "                loss = (loss_per_pos * mask).sum() / mask.sum().clamp(min=1)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Store for metrics\n",
    "            probs = torch.sigmoid(logits)\n",
    "            all_preds.append(probs.cpu().numpy())\n",
    "            all_labels.append(label_batch.cpu().numpy())\n",
    "\n",
    "            if max_batches is not None and (batch_idx + 1) >= max_batches:\n",
    "                break\n",
    "\n",
    "    return total_loss / max(1, (batch_idx + 1)), all_preds, all_labels\n",
    "\n",
    "\n",
    "# Check prerequisites before training\n",
    "required_vars = {\n",
    "    'model': 'model',\n",
    "    'train_loader': 'train_loader', \n",
    "    'val_loader': 'val_loader',\n",
    "    'criterion_weighted': 'criterion_weighted',\n",
    "    'optimizer': 'optimizer',\n",
    "    'device': 'device',\n",
    "    'scaler': 'scaler',\n",
    "    'use_amp': 'use_amp',\n",
    "    'model_filename': 'model_filename'\n",
    "}\n",
    "\n",
    "missing_vars = [var for var, name in required_vars.items() if var not in globals()]\n",
    "if missing_vars:\n",
    "    raise NameError(f\"Missing required variables: {', '.join(missing_vars)}. Please run cells 3-10 in order before training.\")\n",
    "\n",
    "# Training loop (with fast-run controls)\n",
    "epochs = 50  # reduce from 50 for quicker runs\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float(\"inf\")\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "# Limit batches per epoch for faster iteration; set to None to use full dataset\n",
    "max_batches_per_epoch = 100\n",
    "max_eval_batches = 50\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_loss = train_epoch(\n",
    "        model, train_loader, criterion_weighted, optimizer, device,\n",
    "        scaler=scaler, use_amp=use_amp, max_batches=max_batches_per_epoch\n",
    "    )\n",
    "    val_loss, _, _ = validate(\n",
    "        model, val_loader, criterion_weighted, device,\n",
    "        use_amp=use_amp, max_batches=max_eval_batches\n",
    "    )\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), model_filename)\n",
    "        print(f\"  Saved best model to {model_filename}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Plot training history\n",
    "Visualize training and validation loss curves to monitor convergence and detect over/underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(train_losses, label=\"Train Loss\", marker=\"o\")\n",
    "plt.plot(val_losses, label=\"Val Loss\", marker=\"s\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.ylim(0, max(max(train_losses), max(val_losses)) * 1.1)\n",
    "plt.xlim(0, 50)\n",
    "plt.tight_layout()\n",
    "plotter.add_caption(\n",
    "    f\"Training history for {simulation_params.n_samples} reads and {simulation_params.length_bp} bp.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Evaluate on test set\n",
    "Compute metrics on the held-out test data; handle padding and support sklearn or numpy fallbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model_filename = rf\"data/LLM models/test_15000.pt\"\n",
    "model.load_state_dict(torch.load(model_filename))\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "test_loss, test_preds, test_labels = validate(\n",
    "    model, test_loader, criterion_weighted, device\n",
    ")\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Compute metrics\n",
    "all_preds_flat = np.concatenate(test_preds).ravel()\n",
    "all_labels_flat = np.concatenate(test_labels).ravel()\n",
    "\n",
    "# Remove padding positions\n",
    "valid_mask = all_labels_flat >= 0\n",
    "all_preds_flat = all_preds_flat[valid_mask]\n",
    "all_labels_flat = all_labels_flat[valid_mask]\n",
    "\n",
    "# Threshold at 0.3 (lower for imbalanced data with weighted loss)\n",
    "predictions_binary = (all_preds_flat >= 0.3).astype(int)\n",
    "\n",
    "\n",
    "# Metrics: try sklearn, fallback to numpy implementations if missing\n",
    "try:\n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score,\n",
    "        precision_score,\n",
    "        recall_score,\n",
    "        f1_score,\n",
    "        roc_auc_score,\n",
    "    )\n",
    "\n",
    "    sklearn_available = True\n",
    "except Exception as e:\n",
    "    sklearn_available = False\n",
    "    import warnings\n",
    "\n",
    "    warnings.warn(\n",
    "        \"scikit-learn not installed; using numpy fallback for basic metrics. Install with: pip install scikit-learn\"\n",
    "    )\n",
    "\n",
    "    def accuracy_score(y_true, y_pred):\n",
    "        y_true = np.asarray(y_true)\n",
    "        y_pred = np.asarray(y_pred)\n",
    "        return float((y_true == y_pred).mean())\n",
    "\n",
    "    def precision_score(y_true, y_pred, zero_division=0):\n",
    "        y_true = np.asarray(y_true)\n",
    "        y_pred = np.asarray(y_pred)\n",
    "        tp = int(((y_true == 1) & (y_pred == 1)).sum())\n",
    "        fp = int(((y_true == 0) & (y_pred == 1)).sum())\n",
    "        denom = tp + fp\n",
    "        if denom == 0:\n",
    "            return float(zero_division)\n",
    "        return float(tp / denom)\n",
    "\n",
    "    def recall_score(y_true, y_pred, zero_division=0):\n",
    "        y_true = np.asarray(y_true)\n",
    "        y_pred = np.asarray(y_pred)\n",
    "        tp = int(((y_true == 1) & (y_pred == 1)).sum())\n",
    "        fn = int(((y_true == 1) & (y_pred == 0)).sum())\n",
    "        denom = tp + fn\n",
    "        if denom == 0:\n",
    "            return float(zero_division)\n",
    "        return float(tp / denom)\n",
    "\n",
    "    def f1_score(y_true, y_pred, zero_division=0):\n",
    "        p = precision_score(y_true, y_pred, zero_division)\n",
    "        r = recall_score(y_true, y_pred, zero_division)\n",
    "        if (p + r) == 0:\n",
    "            return float(zero_division)\n",
    "        return 2 * (p * r) / (p + r)\n",
    "\n",
    "    def roc_auc_score(y_true, y_score):\n",
    "        y_true = np.asarray(y_true)\n",
    "        y_score = np.asarray(y_score)\n",
    "        # require both classes present\n",
    "        if len(np.unique(y_true)) < 2:\n",
    "            return float(\"nan\")\n",
    "        # Sort scores descending\n",
    "        desc = np.argsort(-y_score)\n",
    "        y_true_sorted = y_true[desc]\n",
    "        # cumulative true/false positives\n",
    "        tp = np.cumsum(y_true_sorted == 1)\n",
    "        fp = np.cumsum(y_true_sorted == 0)\n",
    "        tp_total = tp[-1]\n",
    "        fp_total = fp[-1]\n",
    "        if tp_total == 0 or fp_total == 0:\n",
    "            return float(\"nan\")\n",
    "        tpr = np.concatenate([[0.0], tp / tp_total])\n",
    "        fpr = np.concatenate([[0.0], fp / fp_total])\n",
    "        return float(np.trapz(tpr, fpr))\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "acc = accuracy_score(all_labels_flat, predictions_binary)\n",
    "prec = precision_score(all_labels_flat, predictions_binary, zero_division=0)\n",
    "rec = recall_score(all_labels_flat, predictions_binary, zero_division=0)\n",
    "f1 = f1_score(all_labels_flat, predictions_binary, zero_division=0)\n",
    "auc = roc_auc_score(all_labels_flat, all_preds_flat)\n",
    "\n",
    "print(f\"\\nTest Metrics:\")\n",
    "print(f\"  Accuracy:  {acc:.4f}\")\n",
    "print(f\"  Precision: {prec:.4f}\")\n",
    "print(f\"  Recall:    {rec:.4f}\")\n",
    "print(f\"  F1-Score:  {f1:.4f}\")\n",
    "print(f\"  ROC-AUC:   {auc:.4f}\")\n",
    "\n",
    "# Save test metrics to JSON\n",
    "config_path = Path(model_filename).with_suffix(\".json\")\n",
    "if config_path.exists():\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "else:\n",
    "    config = {}\n",
    "\n",
    "config[\"test_metrics\"] = {\n",
    "    \"n_train_samples\": len(train_indices),\n",
    "    \"n_test_samples\": len(test_indices),\n",
    "    \"n_val_samples\": len(val_indices),\n",
    "    \"n_test_positions\": int(valid_mask.sum()),\n",
    "    \"threshold\": 0.3,\n",
    "    \"test_loss\": float(test_loss),\n",
    "    \"accuracy\": float(acc),\n",
    "    \"precision\": float(prec),\n",
    "    \"recall\": float(rec),\n",
    "    \"f1_score\": float(f1),\n",
    "    \"roc_auc\": float(auc),\n",
    "\n",
    "}\n",
    "\n",
    "with open(config_path, \"w\") as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "print(f\"\\nTest metrics saved to: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Load saved model and predict\n",
    "Reload the trained model and produce dyad probability predictions and visualizations for a new sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dyads(model, encoded_sequence, threshold=0.2, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Predict dyad positions for a single sequence.\n",
    "\n",
    "    Args:\n",
    "        model: trained DyadPredictor\n",
    "        encoded_sequence: list/array of integers (0-7)\n",
    "        threshold: probability threshold for positive class (default 0.5)\n",
    "        device: torch device\n",
    "\n",
    "    Returns:\n",
    "        dyad_positions: list of predicted dyad positions\n",
    "        probabilities: array of per-position probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        seq_tensor = torch.LongTensor(encoded_sequence).unsqueeze(0).to(device)\n",
    "        logits = model(seq_tensor)\n",
    "        probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n",
    "\n",
    "    dyad_positions = np.where(probs >= threshold)[0].tolist()\n",
    "    return dyad_positions, probs\n",
    "\n",
    "\n",
    "# Load config (two-section format: {'simulation': {...}, 'llm': {...}})\n",
    "config_path = Path(model_filename).with_suffix(\".json\")\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "llm_cfg = config.get(\"llm\", {})\n",
    "\n",
    "# Create model from LLM section (keys are prefixed with '_')\n",
    "loaded_model = DyadPredictor(\n",
    "    **{k[1:]: v for k, v in llm_cfg.items() if k.startswith(\"_\")}\n",
    ")\n",
    "loaded_model.load_state_dict(torch.load(model_filename))\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "# Get a random sample from the existing HDF5 file\n",
    "data_params = read_simulation_results(data_filename)\n",
    "idx = np.random.randint(0, data_params.n_samples)\n",
    "dyad_positions_sample, encoded_seq_sample, methylated_seq = read_simulation_results(data_filename, idx)\n",
    "\n",
    "new_seq = encoded_seq_sample\n",
    "\n",
    "dyads, probs = predict_dyads(loaded_model, new_seq, device=device)\n",
    "\n",
    "\n",
    "error = [np.argmax(probs[i - 65 : i + 65]) - 65 for i in dyad_positions_sample]\n",
    "plt.figure(figsize=(12, 1))\n",
    "plt.hist(np.array(error), range=(-30.5, 30.5), bins = 61, color='blue', edgecolor='black')\n",
    "plt.xlabel(\" Error (bp)\")\n",
    "plt.ylabel(\"#\") \n",
    "plt.text(-30, plt.ylim()[1]*0.5, f\"Mean error: {np.mean(error):.2f} bp\\nStd error: {np.std(error):.2f} bp\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "index = np.arange(len(new_seq))\n",
    "nucs = np.zeros_like(index)\n",
    "nucs[dyad_positions_sample] = 1.0\n",
    "\n",
    "for i in dyad_positions_sample:\n",
    "    nucs[i - 65 : i + 65] = -1  # highlight nucleosome region\n",
    "\n",
    "n_plots = 10\n",
    "for i in range(n_plots):\n",
    "    plt.figure(figsize=(12, 1))\n",
    "    plt.xlabel(\"i (bp)\")\n",
    "\n",
    "    plt.vlines(\n",
    "        dyad_positions_sample, ymin=-1, ymax=2, color=\"black\", linestyles=\"dotted\", alpha=1\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        index, probs, label=\"Predicted Dyad Probability\", color=\"orange\", alpha=0.5\n",
    "    )\n",
    "    plt.fill_between(index, nucs, color=\"blue\", alpha=0.5, label=\"True Dyad Positions\")\n",
    "\n",
    "    methylations = np.zeros_like(index)*np.nan\n",
    "    methylations[index[new_seq > 4]] = 1\n",
    "    plt.plot(\n",
    "        index,\n",
    "        methylations,\n",
    "        \"o\",\n",
    "        label=\"methylations\",\n",
    "        color=\"green\",\n",
    "        alpha=0.5,\n",
    "        fillstyle=\"full\",\n",
    "        markersize=3,\n",
    "    )\n",
    "\n",
    "    plt.xlim(i * len(index) // n_plots, (i + 1) * len(index) // n_plots)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.ylim(-0.1, 1.1)\n",
    "\n",
    "    # plt.tight_layout\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 100 fibers and plot a histogram of the difference between predicted and real dyad\n",
    "\n",
    "bins = np.linspace(-30.5, 30.5, 62)\n",
    "all_errors = []\n",
    "n = 100\n",
    "\n",
    "for idx in tqdm(np.random.choice(15000, size=n, replace=False), desc=\"Computing prediction errors\"):\n",
    "    dyad_positions_sample, encoded_seq_sample, methylated_seq = read_simulation_results(data_filename, int(idx))\n",
    "    dyads, probs = predict_dyads(loaded_model, encoded_seq_sample, device=device)\n",
    "    \n",
    "    # For each true dyad, find the closest predicted dyad and compute error\n",
    "    seq_len = len(probs)\n",
    "    for true_dyad in dyad_positions_sample:\n",
    "        error = np.argmax(probs[true_dyad - 65 : true_dyad + 65]) - 65\n",
    "        all_errors.append(error)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(12, 2))\n",
    "plt.hist(all_errors, bins=bins, color='blue', edgecolor='black')\n",
    "plt.xlabel(\"Error (bp)\")\n",
    "plt.ylabel(\"#\") \n",
    "correct = sum(1 for e in all_errors if np.abs(e) <= 0.5) / len(all_errors) * 100\n",
    "plt.text(-30, plt.ylim()[1]*0.5, f\"Mean error: {np.mean(all_errors):.2f} bp\\nStd error: {np.std(all_errors):.2f} bp\\nCorrect = {correct:.0f}%\")\n",
    "plt.xlim(-31, 31)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_gaussians(x, fraction , std):\n",
    "    \"\"\"Model function: sum of three Gaussian distributions.\"\"\"\n",
    "    mean = 0\n",
    "    gauss1 = (fraction /std)* np.exp(-0.5 * ((x - mean) / std) ** 2)\n",
    "    gauss2 = (0.5 * (1 - fraction)/std) * np.exp(-0.5 * ((x - mean -9.5) / std) ** 2)\n",
    "    gauss3 = (0.5 * (1 - fraction)/std) * np.exp(-0.5 * ((x - mean + 9.5) / std) ** 2)\n",
    "    result = gauss1 + gauss2 + gauss3\n",
    "    result = result / np.sum(result)  # Normalize area to 1\n",
    "    result = result / np.median(np.diff(x))\n",
    "    return result\n",
    "\n",
    "histogram, x_hist = np.histogram(all_errors, bins=bins)\n",
    "histogram = histogram / np.sum(histogram)  # Normalize to area=1\n",
    "xhist = (x_hist[:-1] + x_hist[1:]) / 2  # bin centers\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(6, 2))\n",
    "plt.bar(xhist, histogram, width=np.diff(xhist)[0], align=\"center\", alpha=0.4, color='blue', edgecolor='black')\n",
    "plt.xlabel(\"Error (bp)\")\n",
    "plt.ylabel(\"pdf\") \n",
    "correct = sum(1 for e in all_errors if np.abs(e) <= 0.5) / len(all_errors) * 100\n",
    "plt.xlim(-16, 16)\n",
    "\n",
    "three_gaussians_x = np.linspace(-30, 30, 1000)\n",
    "\n",
    "fit_params = {\n",
    "    'fraction': 0.9,\n",
    "    'std': 4.0\n",
    "}\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "popt, pcov = curve_fit(three_gaussians, xhist, histogram, p0=[fit_params['fraction'], fit_params['std']])\n",
    "\n",
    "legend_text = f\"Main peak: {popt[0]:.0%}\\nStd dev.: {popt[1]:.2f} bp\"\n",
    "\n",
    "plt.plot(three_gaussians_x, three_gaussians(three_gaussians_x, *popt), color='red', linewidth=2, label=legend_text, alpha = 0.5)\n",
    "plt.ylim(-0.01, 0.4)\n",
    "plt.legend(fontsize=10, loc='upper right')\n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
