{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d33ed3a9",
   "metadata": {},
   "source": [
    "# Using DyadPredictorLLM Class\n",
    "\n",
    "This notebook demonstrates how to use the `DyadPredictorLLM` class for training and applying dyad prediction models.\n",
    "\n",
    "The class provides a clean interface for:\n",
    "- Creating new models (simple or dilated)\n",
    "- Training on HDF5 data files\n",
    "- Loading pre-trained models from JSON configs\n",
    "- Applying models to predict dyad positions\n",
    "- Visualizing model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17e970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add parent directory to path to import ChromatinFibers\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from DyadPredictorLLM import DyadPredictorLLM\n",
    "from ChromatinFibers import read_simulation_results\n",
    "from Plotter import SequencePlotter\n",
    "\n",
    "plotter = SequencePlotter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda8a045",
   "metadata": {},
   "source": [
    "## Option 1: Create and Train a New Model\n",
    "\n",
    "You can create either a 'simple' or 'dilated' model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aee32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new simple model\n",
    "predictor = DyadPredictorLLM()\n",
    "predictor.init_model(\n",
    "    model_type='simple',  # or 'dilated'\n",
    "    embedding_dim=16,\n",
    "    hidden_dim=64,\n",
    "    num_layers=2,\n",
    "    dropout=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5060b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "data_filename = r\"data/LLM models/test.h5\"\n",
    "\n",
    "predictor.train(\n",
    "    data_filename=data_filename,\n",
    "    model_filename=r\"data/LLM models/my_model.pt\",  # optional, auto-generated if not provided\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    learning_rate=1e-3,\n",
    "    patience=5,\n",
    "    max_batches_per_epoch=100,  # Set to None for full dataset\n",
    "    max_eval_batches=50,  # Set to None for full validation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19710b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "predictor.plot_training_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c286f2a9",
   "metadata": {},
   "source": [
    "## Option 2: Load an Existing Model\n",
    "\n",
    "Load a pre-trained model from a JSON configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from JSON config\n",
    "predictor = DyadPredictorLLM()\n",
    "predictor.load_from_json(r\"data/LLM models/test_15000.json\")\n",
    "\n",
    "# The corresponding .pt file with weights is automatically loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c5f61b",
   "metadata": {},
   "source": [
    "## Visualize Model Architecture\n",
    "\n",
    "See how data flows through the model layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc0bc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.visualize_model(sequence_length=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe75931",
   "metadata": {},
   "source": [
    "## Apply Model to Predict Dyad Positions\n",
    "\n",
    "Use the trained model to predict dyad positions for a specific sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply model to a specific sample\n",
    "result = predictor.apply(\n",
    "    data_filename=r\"data/LLM models/test.h5\",\n",
    "    index=0,  # Sample index in the HDF5 file\n",
    "    threshold=0.3,  # Probability threshold for calling peaks\n",
    "    return_dict=True  # Return full results dictionary\n",
    ")\n",
    "\n",
    "print(f\"Predicted dyad positions: {result['predicted_dyads']}\")\n",
    "print(f\"True dyad positions: {result['true_dyads']}\")\n",
    "print(f\"Number of predictions: {len(result['predicted_dyads'])}\")\n",
    "print(f\"Number of true dyads: {len(result['true_dyads'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8f8200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs ground truth\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 8))\n",
    "\n",
    "# Plot 1: Predicted probabilities\n",
    "axes[0].plot(result['dyad_probabilities'], linewidth=1)\n",
    "axes[0].axhline(0.3, color='red', linestyle='--', label='Threshold')\n",
    "axes[0].set_ylabel('Dyad Probability')\n",
    "axes[0].set_title('Model Predictions')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Predicted dyad positions\n",
    "pred_binary = np.zeros_like(result['dyad_probabilities'])\n",
    "pred_binary[result['predicted_dyads']] = 1\n",
    "axes[1].plot(pred_binary, linewidth=1, color='blue')\n",
    "axes[1].set_ylabel('Predicted Dyad')\n",
    "axes[1].set_ylim(-0.1, 1.1)\n",
    "axes[1].set_title('Predicted Dyad Positions')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: True dyad positions\n",
    "true_binary = np.zeros_like(result['dyad_probabilities'])\n",
    "true_binary[result['true_dyads']] = 1\n",
    "axes[2].plot(true_binary, linewidth=1, color='green')\n",
    "axes[2].set_ylabel('True Dyad')\n",
    "axes[2].set_xlabel('Position (bp)')\n",
    "axes[2].set_ylim(-0.1, 1.1)\n",
    "axes[2].set_title('Ground Truth Dyad Positions')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plotter.add_caption(\"Dyad prediction results for a single sequence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70e280d",
   "metadata": {},
   "source": [
    "## Create a Dilated Model\n",
    "\n",
    "For better multi-scale feature extraction, use the dilated model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f1d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dilated model with larger capacity\n",
    "predictor_dilated = DyadPredictorLLM()\n",
    "predictor_dilated.init_model(\n",
    "    model_type='dilated',\n",
    "    embedding_dim=32,\n",
    "    hidden_dim=128,\n",
    "    num_layers=3,\n",
    "    dropout=0.3,\n",
    "    conv_dilations=(1, 2, 4, 8),  # Multi-scale receptive fields\n",
    "    conv_kernel_size=7\n",
    ")\n",
    "\n",
    "# Train with the same data\n",
    "# predictor_dilated.train(\n",
    "#     data_filename=r\"data/LLM models/test.h5\",\n",
    "#     epochs=50,\n",
    "#     batch_size=32,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61c33f5",
   "metadata": {},
   "source": [
    "## Batch Prediction\n",
    "\n",
    "Apply the model to multiple sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dc8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for multiple samples\n",
    "n_samples = 5\n",
    "results = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    result = predictor.apply(\n",
    "        data_filename=r\"data/LLM models/test.h5\",\n",
    "        index=i,\n",
    "        threshold=0.3,\n",
    "        return_dict=True\n",
    "    )\n",
    "    results.append(result)\n",
    "    print(f\"Sample {i}: Predicted {len(result['predicted_dyads'])} dyads, \"\n",
    "          f\"True {len(result['true_dyads'])} dyads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cde22f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average metrics across samples\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "for result in results:\n",
    "    seq_len = len(result['dyad_probabilities'])\n",
    "    \n",
    "    # Create binary arrays\n",
    "    y_true = np.zeros(seq_len)\n",
    "    y_true[result['true_dyads']] = 1\n",
    "    \n",
    "    y_pred = np.zeros(seq_len)\n",
    "    y_pred[result['predicted_dyads']] = 1\n",
    "    \n",
    "    # Calculate metrics\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(f\"\\nAverage Metrics (n={n_samples}):\")\n",
    "print(f\"  Precision: {np.mean(precisions):.4f} ± {np.std(precisions):.4f}\")\n",
    "print(f\"  Recall:    {np.mean(recalls):.4f} ± {np.std(recalls):.4f}\")\n",
    "print(f\"  F1-Score:  {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f3779",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The `DyadPredictorLLM` class provides:\n",
    "\n",
    "1. **`.init_model()`** - Initialize a new model with specified architecture\n",
    "2. **`.load_from_json()`** - Load a pre-trained model from JSON config\n",
    "3. **`.train()`** - Train the model on HDF5 data with automatic checkpointing\n",
    "4. **`.apply()`** - Predict dyad positions for a specific sequence\n",
    "5. **`.visualize_model()`** - Visualize the model architecture\n",
    "6. **`.plot_training_history()`** - Plot training/validation loss curves\n",
    "\n",
    "The class handles both 'simple' and 'dilated' model architectures, manages data loading from HDF5 files, and provides a clean API for all common tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
